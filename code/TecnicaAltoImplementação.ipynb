{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#importando Bibliotecas"
      ],
      "metadata": {
        "id": "istqasHLXG7M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zO_UudBgZ5zv"
      },
      "outputs": [],
      "source": [
        "# Importar bibliotecas de manipulação de dados\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Importar detectores de outliers\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.linear_model import SGDOneClassSVM\n",
        "\n",
        "# Importar indicadores de qualidade de clusterização\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import calinski_harabasz_score\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Importar indicadores de desempenho de classificação\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Importar bibliotecas adicionais\n",
        "from time import sleep\n",
        "import math\n",
        "import csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsWefqy7Z5zw"
      },
      "source": [
        "#Funções auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kknDc3ydZ5zx"
      },
      "outputs": [],
      "source": [
        "# Função para criar um arquivo CSV\n",
        "def criar_csv(nome_arquivo, cabecalho):\n",
        "    with open(nome_arquivo, 'w', newline='') as arquivo_csv:\n",
        "        escritor_csv = csv.writer(arquivo_csv)\n",
        "        escritor_csv.writerow(cabecalho)\n",
        "# Função para abrir um arquivo CSV existente e adicionar novos dados\n",
        "\n",
        "def abrir_csv_para_edicao(nome_arquivo):\n",
        "    with open(nome_arquivo, 'a', newline='') as arquivo_csv:\n",
        "        escritor_csv = csv.writer(arquivo_csv)\n",
        "        #OneClassSVM\n",
        "        array_kernel = ['linear' , 'poly' , 'rbf' ]\n",
        "        nu_atual = 0.01\n",
        "        for c in array_kernel:\n",
        "            while nu_atual <= 0.5:\n",
        "              y_test = OneClassSVM(gamma='auto', kernel=c, nu=nu_atual).fit_predict(x_train)\n",
        "              y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
        "\n",
        "              if(sum(y_test_final) > 0 and 0 in y_test_final):\n",
        "\n",
        "                #Silhouette Coeficient\n",
        "                silhouette_value = silhouette_score(x_train, y_test_final, metric='euclidean')\n",
        "\n",
        "                #calinski Score\n",
        "                calinski_value = calinski_harabasz_score(x_train, y_test_final)\n",
        "\n",
        "                #Davies\n",
        "                davies_value = davies_bouldin_score(x_train, y_test_final)\n",
        "\n",
        "                linha = 'OneClassSVM,' + \"kernel;\" +c+ ';nu;' + str(nu_atual) + ',' + str(silhouette_value) + ',' + str(calinski_value) + ',' + str(davies_value)\n",
        "                dados = linha.split(',')\n",
        "                escritor_csv.writerow(dados)\n",
        "                nu_atual =  round(nu_atual + 0.001 ,3)\n",
        "            nu_atual = 0.01\n",
        "        #SGDOneClassSVM\n",
        "        learning_rate = ['constant','optimal', 'invscaling' ,'adaptive']\n",
        "\n",
        "        nu_atual = 0.01\n",
        "        for c in learning_rate:\n",
        "          while (nu_atual <= 0.5):\n",
        "\n",
        "            y_test = SGDOneClassSVM(learning_rate = c, nu = nu_atual, eta0= 0.1, random_state=0).fit_predict(x_train)\n",
        "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
        "            if(sum(y_test_final) > 0 and 0 in y_test_final):\n",
        "              #Silhouette Coeficient\n",
        "              silhouette_value = silhouette_score(x_train, y_test_final, metric='euclidean')\n",
        "\n",
        "              #calinski Score\n",
        "              calinski_value = calinski_harabasz_score(x_train, y_test_final)\n",
        "\n",
        "              #Davies\n",
        "              davies_value = davies_bouldin_score(x_train, y_test_final)\n",
        "\n",
        "              linha = 'SGDOneClassSVM,' + \"Learning_rate;\" +c+ ';nu;' + str(nu_atual) + ',' + str(silhouette_value) + ',' + str(calinski_value) + ',' + str(davies_value)\n",
        "              dados = linha.split(',')\n",
        "              escritor_csv.writerow(dados)\n",
        "            nu_atual =  round(nu_atual + 0.001 ,3)\n",
        "          nu_atual = 0.01\n",
        "\n",
        "\n",
        "        array_algorithm = ['auto', 'ball_tree', 'kd_tree','brute']\n",
        "\n",
        "        for c in array_algorithm:\n",
        "          b = 0\n",
        "          while b < 10:\n",
        "            b = b + 1\n",
        "            y_test = LocalOutlierFactor(n_neighbors=b, algorithm = c).fit_predict(x_train)\n",
        "            y_test_final = [0 if i == 1 else 1 for i in y_test]\n",
        "\n",
        "            if(sum(y_test_final) > 0 and 0 in y_test_final):\n",
        "              #Silhouette Coeficient\n",
        "              silhouette_value = silhouette_score(x_train, y_test_final, metric='euclidean')\n",
        "\n",
        "              #calinski Score\n",
        "              calinski_value = calinski_harabasz_score(x_train, y_test_final)\n",
        "\n",
        "              #Davies\n",
        "              davies_value = davies_bouldin_score(x_train, y_test_final)\n",
        "              linha = 'LocalOutlierFactor,' + \"array_algorithm;\" + c + \";\"+ \"n_neighbors;\" +str(b)+ ',' + str(silhouette_value) + ',' + str(calinski_value) + ',' + str(davies_value)\n",
        "              dados = linha.split(',')\n",
        "              escritor_csv.writerow(dados)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def manipulacao( nomeArq ):\n",
        "  csv_dados = nomeArq\n",
        "  csv = pd.read_csv(csv_dados, sep=\",\")\n",
        "\n",
        "  Colunas = ['Silhouette','Calinski','Davies']\n",
        "  data = csv[Colunas]\n",
        "  scaler = MinMaxScaler()\n",
        "  scaler.fit(data)\n",
        "  x = scaler.transform(data)\n",
        "  Silhouette = x[:,0:1]\n",
        "  Calinski =  x[:,1:2]\n",
        "  Davies =  x[:,2:3]\n",
        "\n",
        "\n",
        "\n",
        "  Silhouette = Silhouette.reshape(Silhouette.shape[1],Silhouette.shape[0])[0]\n",
        "  Calinski = Calinski.reshape(Calinski.shape[1],Calinski.shape[0])[0]\n",
        "  Davies = Davies.reshape(Davies.shape[1],Davies.shape[0])[0]\n",
        "\n",
        "  Davies = 1-Davies\n",
        "\n",
        "  Media_indicadores = (Calinski + Silhouette)/2\n",
        "\n",
        "  df = pd.read_csv(nomeArq)\n",
        "\n",
        "  # Criar os dados para as novas colunas\n",
        "  novas_colunas = {\n",
        "      'Silhouette_normalizado': Silhouette,\n",
        "      'Calinski_normalizado': Calinski,\n",
        "      'Davies_normalizado': Davies,\n",
        "      'Media_indicadores': Media_indicadores\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "  # Converter o dicionário para um DataFrame\n",
        "  df_novas_colunas = pd.DataFrame(novas_colunas)\n",
        "\n",
        "  # Concatenar os DataFrames ao longo das colunas (axis=1)\n",
        "  df_concatenado = pd.concat([df, df_novas_colunas], axis=1)\n",
        "\n",
        "\n",
        "  Colunas = ['Modelo','Parametros','Silhouette_normalizado','Davies_normalizado','Calinski_normalizado','Media_indicadores']\n",
        "  Data_Select_db = df_concatenado[Colunas]\n",
        "  Data_Select_db_ordenado = Data_Select_db.sort_values(by='Media_indicadores',ascending = False)\n",
        "  x = Data_Select_db_ordenado.iloc[0][1].split(';')\n",
        "\n",
        "\n",
        "\n",
        "  if Data_Select_db_ordenado.iloc[0][0] == \"OneClassSVM\":\n",
        "    clf = OneClassSVM(kernel = x[1], nu= float(x[3])).fit(x_train)\n",
        "    y_test = clf.predict(x_test)\n",
        "    y_atual = [0 if i == 1 else 1 for i in y_test]\n",
        "    print(confusion_matrix(y_real, y_atual))\n",
        "    print(classification_report(y_real, y_atual, digits = 4))\n",
        "  if Data_Select_db_ordenado.iloc[0][0] == \"SGDOneClassSVM\":\n",
        "    clf = SGDOneClassSVM(learning_rate = x[1], nu= float(x[3]), eta0= 0.1 ).fit(x_train)\n",
        "    y_test = clf.predict(x_test)\n",
        "    y_atual = [0 if i == 1 else 1 for i in y_test]\n",
        "    print(confusion_matrix(y_real, y_atual))\n",
        "    print(classification_report(y_real, y_atual, digits = 4))\n",
        "  if Data_Select_db_ordenado.iloc[0][0] == \"LocalOutlierFactor\":\n",
        "    clf = LocalOutlierFactor(array_algorithm = x[1], n_neighbors= int(x[3])).fit(x_train)\n",
        "    y_test = clf.predict(x_test)\n",
        "    y_atual = [0 if i == 1 else 1 for i in y_test]\n",
        "    print(confusion_matrix(y_real, y_atual))\n",
        "    print(classification_report(y_real, y_atual, digits = 4))\n",
        "  if Data_Select_db_ordenado.iloc[0][0] == \"EllipticEnvelope\":\n",
        "    clf = EllipticEnvelope(contamination = float(x[1])).fit(x_train)\n",
        "    y_test = clf.predict(x_test)\n",
        "    y_atual = [0 if i == 1 else 1 for i in y_test]\n",
        "    print(confusion_matrix(y_real, y_atual))\n",
        "    print(classification_report(y_real, y_atual, digits = 4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experimento 1"
      ],
      "metadata": {
        "id": "itlIBdWgXnk9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "waVl1EulZ5zw"
      },
      "outputs": [],
      "source": [
        "#cap_51\n",
        "early_warning_url = \"cap_51_outlier_10.csv\"\n",
        "early_warning = pd.read_csv(early_warning_url, sep=\";\")\n",
        "file = \"10\"\n",
        "colunas = [file+'_kurt_total_ips_origem',\n",
        "           file+'_skw_total_ips_origem',\n",
        "           file+'_coefficient_variation_total_ips_origem',\n",
        "           file+'_kurt_total_ips_destino',\n",
        "           file+'_skw_total_ips_destino',\n",
        "           file+'_coefficient_variation_total_ips_destino',\n",
        "           file+'_kurt_total_pacotes',\n",
        "           file+'_skw_total_pacotes',\n",
        "           file+'_coefficient_variation_total_pacotes',\n",
        "              ]\n",
        "df = early_warning[colunas]\n",
        "label = early_warning['has_bot']\n",
        "\n",
        "init = 880\n",
        "train = 2934\n",
        "end = 5632\n",
        "\n",
        "x_train = df[init:train]\n",
        "x_test = df[train:end]\n",
        "y_real = label[train:end]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13imJYY_Z5zx"
      },
      "source": [
        "##Executando extração indicadores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "03v2HCMDZ5zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f606e54c-ee19-4191-fa50-3c6b132ee01d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo CSV criado e editado com sucesso!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-04aa7acf8279>:131: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  x = Data_Select_db_ordenado.iloc[0][1].split(';')\n",
            "<ipython-input-16-04aa7acf8279>:135: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  if Data_Select_db_ordenado.iloc[0][0] == \"OneClassSVM\":\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2415   67]\n",
            " [ 204   12]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9221    0.9730    0.9469      2482\n",
            "           1     0.1519    0.0556    0.0814       216\n",
            "\n",
            "    accuracy                         0.8996      2698\n",
            "   macro avg     0.5370    0.5143    0.5141      2698\n",
            "weighted avg     0.8604    0.8996    0.8776      2698\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-04aa7acf8279>:141: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  if Data_Select_db_ordenado.iloc[0][0] == \"SGDOneClassSVM\":\n",
            "<ipython-input-16-04aa7acf8279>:147: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  if Data_Select_db_ordenado.iloc[0][0] == \"LocalOutlierFactor\":\n",
            "<ipython-input-16-04aa7acf8279>:153: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  if Data_Select_db_ordenado.iloc[0][0] == \"EllipticEnvelope\":\n"
          ]
        }
      ],
      "source": [
        "# Nome do arquivo CSV e cabeçalho\n",
        "nome_arquivo = 'dados_ctu13.csv'\n",
        "cabecalho = ['Modelo', 'Parametros', 'Silhouette', 'Calinski', 'Davies' ]\n",
        "\n",
        "# Criar o arquivo CSV com o cabeçalho\n",
        "criar_csv(nome_arquivo, cabecalho)\n",
        "\n",
        "# Abrir o arquivo CSV para edição\n",
        "abrir_csv_para_edicao(nome_arquivo)\n",
        "\n",
        "print(\"Arquivo CSV criado e editado com sucesso!\")\n",
        "\n",
        "manipulacao(nome_arquivo)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experimento 2"
      ],
      "metadata": {
        "id": "KvbC-k1WXvBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nn6FM2bDXvBy"
      },
      "outputs": [],
      "source": [
        "#cic\n",
        "early_warning_url = \"cicddos_outlier_10.csv\"\n",
        "early_warning = pd.read_csv(early_warning_url, sep=\";\")\n",
        "file = \"10\"\n",
        "colunas = [file+'_kurt_total_ips_origem',\n",
        "           file+'_skw_total_ips_origem',\n",
        "           file+'_coefficient_variation_total_ips_origem',\n",
        "           file+'_kurt_total_ips_destino',\n",
        "           file+'_skw_total_ips_destino',\n",
        "           file+'_coefficient_variation_total_ips_destino',\n",
        "           file+'_kurt_total_pacotes',\n",
        "           file+'_skw_total_pacotes',\n",
        "           file+'_coefficient_variation_total_pacotes',\n",
        "              ]\n",
        "df = early_warning[colunas]\n",
        "label = early_warning['has_bot']\n",
        "\n",
        "\n",
        "init = 202\n",
        "train = 674\n",
        "end = 1484\n",
        "\n",
        "x_train = df[init:train]\n",
        "x_test = df[train:end]\n",
        "y_real = label[train:end]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKFOQztpXvCN"
      },
      "source": [
        "##Executando extração indicadores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "007e785c-626d-4214-e531-101c05cc3a0e",
        "id": "2ZVe0b7CXvCN"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo CSV criado e editado com sucesso!\n",
            "[[531  29]\n",
            " [239  11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6896    0.9482    0.7985       560\n",
            "           1     0.2750    0.0440    0.0759       250\n",
            "\n",
            "    accuracy                         0.6691       810\n",
            "   macro avg     0.4823    0.4961    0.4372       810\n",
            "weighted avg     0.5616    0.6691    0.5755       810\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-04aa7acf8279>:131: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  x = Data_Select_db_ordenado.iloc[0][1].split(';')\n",
            "<ipython-input-16-04aa7acf8279>:135: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  if Data_Select_db_ordenado.iloc[0][0] == \"OneClassSVM\":\n",
            "<ipython-input-16-04aa7acf8279>:141: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  if Data_Select_db_ordenado.iloc[0][0] == \"SGDOneClassSVM\":\n",
            "<ipython-input-16-04aa7acf8279>:147: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  if Data_Select_db_ordenado.iloc[0][0] == \"LocalOutlierFactor\":\n",
            "<ipython-input-16-04aa7acf8279>:153: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  if Data_Select_db_ordenado.iloc[0][0] == \"EllipticEnvelope\":\n"
          ]
        }
      ],
      "source": [
        "# Nome do arquivo CSV e cabeçalho\n",
        "nome_arquivo = 'dados_cic.csv'\n",
        "cabecalho = ['Modelo', 'Parametros', 'Silhouette', 'Calinski', 'Davies' ]\n",
        "\n",
        "# Criar o arquivo CSV com o cabeçalho\n",
        "criar_csv(nome_arquivo, cabecalho)\n",
        "\n",
        "# Abrir o arquivo CSV para edição\n",
        "abrir_csv_para_edicao(nome_arquivo)\n",
        "\n",
        "print(\"Arquivo CSV criado e editado com sucesso!\")\n",
        "\n",
        "manipulacao(nome_arquivo)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar e treinar o modelo SGD One-Class SVM\n",
        "clf = SGDOneClassSVM(learning_rate='adaptive', eta0=0.1, nu=0.474 ).fit(x_train)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_test = clf.predict(x_test)\n",
        "\n",
        "# Converter as previsões para o formato esperado (0 para normal, 1 para outlier)\n",
        "y_atual = [0 if i == 1 else 1 for i in y_test]\n",
        "\n",
        "# Imprimir a matriz de confusão e o relatório de classificação\n",
        "print(confusion_matrix(y_real, y_atual))\n",
        "print(classification_report(y_real, y_atual, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXMxmPUSeLPh",
        "outputId": "6ff62841-85c7-4646-80f3-56583c47da26"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[532  28]\n",
            " [239  11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6900    0.9500    0.7994       560\n",
            "           1     0.2821    0.0440    0.0761       250\n",
            "\n",
            "    accuracy                         0.6704       810\n",
            "   macro avg     0.4860    0.4970    0.4378       810\n",
            "weighted avg     0.5641    0.6704    0.5762       810\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "istqasHLXG7M",
        "fsWefqy7Z5zw",
        "itlIBdWgXnk9",
        "KvbC-k1WXvBx"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}